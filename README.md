ğŸ“˜ Multi-Modal RAG Question-Answering System

A Retrieval-Augmented Generation (RAG) system built for querying complex PDF documents containing text, tables, figures, and metadata.
Live Demo â†’ https://multimodelrag-fdwwe2ev2afwkrlbdwwny5.streamlit.app/

ğŸš€ Overview

This project implements a multi-modal Retrieval-Augmented Generation (RAG) pipeline capable of answering user questions strictly using information extracted from a complex PDF, such as IMF country reports.

The system performs:

PDF extraction (text + tables + structured content)

Chunking into semantically meaningful segments

Embedding using Sentence-BERT (local) or TF-IDF fallback

Vector search using FAISS when available

Reranking with TF-IDF cross-similarity

Strict evidence-based prompting to prevent hallucinations

LLM answer generation using Gemini Flash

Verification step to block unsupported answers

Streamlit UI for an interactive search experience

The entire pipeline is optimized for high accuracy retrieval, low hallucination, and cloud-friendly execution.

ğŸ§© System Architecture
1ï¸âƒ£ PDF Extraction

Located in src/extract.py

Extracts text, tables, and structural elements

Saves chunk metadata into data/meta.jsonl

Saves raw chunks into data/pages.jsonl

2ï¸âƒ£ Chunking

Located in src/chunks.py

Splits long PDF segments into short, overlapping, context-preserving chunks

Handles tables, paragraphs, and captions

3ï¸âƒ£ Embeddings

Located in src/embeddings.py

Generates embeddings using:

SentenceTransformer (all-MiniLM-L6-v2) when available

TF-IDF vectorizer fallback when heavy ML models cannot load (Streamlit Cloud friendly)

4ï¸âƒ£ Vector Index

Located in src/vector_index.py

FAISS-like nearest-neighbors retrieval

Automatically falls back if FAISS unavailable

5ï¸âƒ£ RAG Pipeline

ğŸš© Most important file: src/rag.py

Features:

Multi-strategy retrieval (vector â†’ SBERT â†’ TF-IDF)

TF-IDF reranking

Strict evidence-only prompt construction

Evidence-verification heuristic

Modular design for easy debugging

6ï¸âƒ£ Streamlit Interface

Located in src/app.py

Handles user input

Displays retrieved evidence

Streams generated answer

Runs seamlessly on Streamlit Cloud

ğŸ§  Example Questions You Can Ask

Try these on the live app:

â€œWhat is the projected GDP growth for Qatar in 2024-25?â€

â€œWhat risks are highlighted in the IMF report?â€

â€œWhat reforms are included in Qatarâ€™s Third National Development Strategy (NDS3)?â€

â€œHow did Qatar's banking sector perform in 2023?â€

ğŸ“ Project Structure
multi_modal_rag/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ qatar.pdf
â”‚   â”œâ”€â”€ meta.jsonl
â”‚   â”œâ”€â”€ pages.jsonl
â”‚   â””â”€â”€ embeddings.npy
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py               # Streamlit interface
â”‚   â”œâ”€â”€ extract.py           # PDF extraction
â”‚   â”œâ”€â”€ chunks.py            # Chunk generation
â”‚   â”œâ”€â”€ embeddings.py        # Embedding generation
â”‚   â”œâ”€â”€ indexing.py          # Vector index builder
â”‚   â”œâ”€â”€ vector_index.py      # Lightweight FAISS-like search
â”‚   â””â”€â”€ rag.py               # ğŸ”¥ Core retrieval+prompt pipeline
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ§ª How to Run Locally
1. Clone repository
git clone https://github.com/HarshilUndhad/Multi_Model_Rag.git
cd Multi_Model_Rag

2. Create virtual environment
python -m venv venv
venv\Scripts\activate   # Windows

3. Install requirements
pip install -r requirements.txt

4. Add your Gemini API key

Create a .env file:

GOOGLE_API_KEY=your_key_here

5. Run Streamlit app
streamlit run src/app.py

ğŸŒ Deployment

The project is deployed on Streamlit Cloud, using the same structure as local execution.

Live App Link:

ğŸ‘‰ https://multimodelrag-fdwwe2ev2afwkrlbdwwny5.streamlit.app/
ğŸ› ï¸ Technologies Used

Python 3

Streamlit

SentenceTransformers

Scikit-Learn (TF-IDF)

NumPy

FAISS / custom vector index

Google Gemini API

ğŸ§© Key Features / Highlights
âœ” Multi-modal PDF understanding

Extracts text, tables, captions, and structured metadata.

âœ” Reliable retrieval stack

Try vector index

Try SBERT embeddings

Fall back to TF-IDF

Then rerank for best results

âœ” Strict anti-hallucination design

Evidence-only prompt

Limited chunk size

Reranking

Verification step

âœ” Cloud-optimized

Runs even on Streamlit Cloud without GPU.

ğŸ“œ Limitations

Images in PDF are not semantically interpreted (OCR/Tesseract can be added later).

No cross-chunk global reasoning (can be added with long-context LLM).

Table extraction depends on PDF structure quality.
